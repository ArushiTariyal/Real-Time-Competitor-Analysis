{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6PS21y8u19KjzNi3D3K7w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArushiTariyal/Real-Time-Competitor-Analysis/blob/main/scrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBV8Fq3GudRk",
        "outputId": "b11e283b-1d79-42d2-da94-a7cc93214ea3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2024.12.14)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.1.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.28.1 sortedcontainers-2.4.0 trio-0.28.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_UTP377uRvy",
        "outputId": "8f3ce35b-0148-485b-ed8e-4da2b1fb1c42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.24.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.41.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install webdriver_manager"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4qyW2lGup-D",
        "outputId": "02279abe-461a-4e64-997e-016431278efc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting webdriver_manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver_manager) (2.32.3)\n",
            "Collecting python-dotenv (from webdriver_manager)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver_manager) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver_manager) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver_manager) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver_manager) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver_manager) (2024.12.14)\n",
            "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, webdriver_manager\n",
            "Successfully installed python-dotenv-1.0.1 webdriver_manager-4.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromedriver_autoinstaller"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTlTkGH1u2g5",
        "outputId": "483c8c2c-a57c-4773-c45f-e84742a37fe6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromedriver_autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from chromedriver_autoinstaller) (24.2)\n",
            "Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: chromedriver_autoinstaller\n",
            "Successfully installed chromedriver_autoinstaller-0.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "kHhN2GeXuG60",
        "outputId": "11a7ad1a-60d2-4213-aa5a-bbf22796e0f6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'set' object has no attribute 'items'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-14eae8e323fe>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mproduct_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mproduct_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_product_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'set' object has no attribute 'items'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import requests\n",
        "import plotly.express as px\n",
        "import streamlit as st\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.support.wait import WebDriverWait\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "import chromedriver_autoinstaller\n",
        "from transformers import pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "\n",
        "links={\"https://www.amazon.in/Apple-iPhone-13-128GB-Green/dp/B09V4B6K53/ref=sr_1_1_sspa?crid=2XWF6OQBE9MW2&dib=eyJ2IjoiMSJ9.4Amcm6ymShwYf2cUNy6g87ZAmr160niWSMsGfJ6ktkhVvBfKClhwZifyFoyaaxp3p9CgrK4JD0kka6vg2gnarqoOb62duNBPCD13Tp0i69vRDmk4uzfDB-25bgoJNhIMNFEoNjBAjmfxVst_C0QmW8zulZt3XeCwXmXb04f26KHMlZ8v3WYOdj3IywjwNuQ1kRaqWcGGKYG5719prdWaQTuqcco0NBNjnzPCNlPyH_Y.GrzT8mZU2IyaErRyD0CZZeRLmD9_fnsrr95RqbZorhw&dib_tag=se&keywords=iphone&qid=1737998659&sprefix=iphone%2Caps%2C238&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&th=1\",\n",
        "    }\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "\n",
        "def get_driver():\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument(\"--headless\")\n",
        "    chrome_options.add_argument(\"--no-sandbox\")\n",
        "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    # Automatically install the chromedriver version that matches the chromium version\n",
        "    chromedriver_autoinstaller.install()\n",
        "\n",
        "    # Create the webdriver with the options and use the default path\n",
        "    driver = webdriver.Chrome(options=chrome_options)\n",
        "    return driver\n",
        "\n",
        "\n",
        "def scrape_product_data(link):\n",
        "    driver = get_driver()\n",
        "    driver.set_window_size(1920, 1080)\n",
        "    driver.get(link)\n",
        "    product_data = {\n",
        "        \"product_name\": \"\",  # Add product_name to the dictionary\n",
        "        \"selling price\": 0,\n",
        "        \"original price\": 0,\n",
        "        \"discount\": 0,\n",
        "        \"rating\": 0,\n",
        "        \"reviews\": [],\n",
        "        \"product_url\": link,\n",
        "    }\n",
        "    retry = 0\n",
        "    while retry < 3:\n",
        "        try:\n",
        "            driver.save_screenshot(\"screenshot.png\")\n",
        "            wait = WebDriverWait(driver, 10)\n",
        "            wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"a-offscreen\")))\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"Retrying... Error: {e}\")\n",
        "            retry += 1\n",
        "            driver.get(link)\n",
        "            time.sleep(5)\n",
        "\n",
        "    try:\n",
        "        price_elem = driver.find_element(\n",
        "            By.XPATH, '//*[@id=\"corePriceDisplay_desktop_feature_div\"]/div[1]/span[3]/span[2]/span[2]'\n",
        "        )\n",
        "        product_data[\"selling price\"] = int(\"\".join(price_elem.text.strip().split(\",\")))\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting selling price: {e}\")\n",
        "\n",
        "    try:\n",
        "        original_price = driver.find_element(\n",
        "            By.XPATH, '//*[@id=\"corePriceDisplay_desktop_feature_div\"]/div[2]/span/span[1]/span[2]/span/span[2]'\n",
        "        ).text\n",
        "        product_data[\"original price\"] = int(\"\".join(original_price.strip().split(\",\")))\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting original price: {e}\")\n",
        "\n",
        "    try:\n",
        "        discount = driver.find_element(\n",
        "            By.XPATH, '//*[@id=\"corePriceDisplay_desktop_feature_div\"]/div[1]/span[2]'\n",
        "        )\n",
        "        full_rating_text = discount.get_attribute(\"innerHTML\").strip()\n",
        "        if \" out of 5 stars\" in full_rating_text.lower():\n",
        "            product_data[\"rating\"] = full_rating_text.lower().split(\" out of\")[0].strip()\n",
        "        else:\n",
        "            product_data[\"discount\"] = full_rating_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting discount: {e}\")\n",
        "\n",
        "    try:\n",
        "        driver.find_element(By.CLASS_NAME, \"a-icon-popover\").click()\n",
        "        time.sleep(1)\n",
        "    except Exception as e:\n",
        "        print(f\"Error clicking rating popover: {e}\")\n",
        "\n",
        "    try:\n",
        "        reviews_link = driver.find_elements(\n",
        "            By.XPATH, \"//a[contains(text(), 'See customer reviews')]\"\n",
        "        )[-1].get_attribute(\"href\")\n",
        "        product_data[\"product_url\"] = reviews_link.split(\"#\")[0]\n",
        "        driver.get(reviews_link)\n",
        "        time.sleep(3)\n",
        "        reviews = driver.find_element(By.ID, \"cm-cr-dp-review-list\")\n",
        "        reviews = reviews.find_elements(By.TAG_NAME, \"li\")\n",
        "        for item in reviews:\n",
        "            product_data[\"reviews\"].append(item.get_attribute(\"innerText\"))\n",
        "        driver.back()\n",
        "        time.sleep(3)\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting reviews: {e}\")\n",
        "\n",
        "    driver.quit()\n",
        "    return product_data\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "def extract_rating_from_review(review_text):\n",
        "    match = re.search(r\"(\\d+\\.\\d+) out of 5 stars\", review_text)\n",
        "    if match:\n",
        "        return float(match.group(1))\n",
        "    return None\n",
        "\n",
        "for product_name, link in links.items():\n",
        "    product_data = scrape_product_data(link)\n",
        "\n",
        "    # Update reviews.csv\n",
        "    try:\n",
        "        reviews_df = pd.read_csv(\"reviews.csv\")\n",
        "    except FileNotFoundError:\n",
        "        reviews_df = pd.DataFrame(columns=[\"product_name\", \"review\", \"rating\", \"date\"])\n",
        "\n",
        "    new_reviews = []\n",
        "    for review_text in product_data[\"reviews\"]:\n",
        "        rating = extract_rating_from_review(review_text)\n",
        "        new_reviews.append({\n",
        "            \"product_name\": product_name,\n",
        "            \"review\": review_text,\n",
        "            \"rating\": rating,\n",
        "            \"date\": datetime.now().strftime(\"%Y-%m-%d\")\n",
        "        })\n",
        "\n",
        "    new_reviews_df = pd.DataFrame(new_reviews)\n",
        "    reviews_df = pd.concat([reviews_df, new_reviews_df], ignore_index=True)\n",
        "    reviews_df.to_csv(\"reviews.csv\", index=False)\n",
        "\n",
        "    # Update competitor_data.csv\n",
        "    try:\n",
        "        competitor_df = pd.read_csv(\"competitor_data.csv\")\n",
        "    except FileNotFoundError:\n",
        "        competitor_df = pd.DataFrame(columns=[\"product_name\", \"price\", \"discount\", \"date\"])\n",
        "\n",
        "    new_data = {\n",
        "        \"product_name\": product_name,\n",
        "        \"price\": product_data[\"selling price\"],\n",
        "        \"discount\": product_data[\"discount\"],\n",
        "        \"date\": datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    }\n",
        "\n",
        "    new_data_df = pd.DataFrame([new_data])\n",
        "    competitor_df = pd.concat([competitor_df, new_data_df], ignore_index=True)\n",
        "    competitor_df.to_csv(\"competitor_data.csv\", index=False)\n",
        "\n",
        "# API keys\n",
        "API_KEY = \"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\"  # Groq API Key\n",
        "SLACK_WEBHOOK = \"xoxe.xoxp-1-Mi0yLTgzNjMxNDY1MTEwMjgtODM3MzMxODc4NzI5Ny04Mzg1NTc0Mjg4ODUxLTgzODgxODkwNzUxMjQtOWVlODU0MzVhOWJiZjk3ZTAzM2JkNzdkNjVhNjE2MTViOTM3ZWRjMzc3MGRiYjI3ZDQ0MzhmM2FhNzNlYjkyZA\"  # Slack webhook URL\n",
        "# Streamlit app setup\n",
        "st.set_page_config(layout=\"wide\")\n",
        "# Create two columns\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "# Add content to the first column\n",
        "with col1:\n",
        "     st.markdown(\n",
        "        \"\"\"\n",
        "        <div style=\"font-size: 40px; text-align: left; width: 100%;\">\n",
        "            ❄️❄️❄️<strong>E-Commerce Competitor Strategy Dashboard</strong>❄️❄️❄️\n",
        "        </div>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True,\n",
        "    )\n",
        "\n",
        "# Add GIF to the second column\n",
        "with col2:\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "        <div style=\"text-align: right;\">\n",
        "            <img src=\"https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExbzh4dXpuc2hpY3JlNnR1MDdiMXozMXlreHFoZjl0a2g5anJqNWxtMCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/hWe6YajFuxX41eV8I0/giphy.gif\" alt=\"Engaging GIF\" width=\"300\">\n",
        "        </div>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True,\n",
        "    )\n",
        "\n",
        "# Utility function to truncate text\n",
        "def truncate_text(text, max_length=512):\n",
        "    return text[:max_length]\n",
        "\n",
        "# Load competitor data\n",
        "def load_competitor_data():\n",
        "    \"\"\"Load competitor data from a CSV file.\"\"\"\n",
        "    data = pd.read_csv(\"competitor_data.csv\")\n",
        "    st.write(data.head())  # Display data for debugging\n",
        "    return data\n",
        "\n",
        "# Load reviews data\n",
        "def load_reviews_data():\n",
        "    \"\"\"Load reviews data from a CSV file.\"\"\"\n",
        "    reviews = pd.read_csv(\"reviews.csv\")\n",
        "    return reviews\n",
        "\n",
        "# Analyze customer sentiment\n",
        "def analyze_sentiment(reviews):\n",
        "    \"\"\"Analyze customer sentiment for reviews.\"\"\"\n",
        "    sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "    return sentiment_pipeline(reviews)\n",
        "\n",
        "# Train predictive model\n",
        "def train_predictive_model(data):\n",
        "    \"\"\"Train a predictive model for competitor pricing strategy.\"\"\"\n",
        "    data[\"Discount\"] = data[\"Discount\"].str.replace(\"%\", \"\").astype(float)\n",
        "    data[\"Price\"] = data[\"Price\"].astype(float)\n",
        "    data[\"Predicted_Discount\"] = data[\"Discount\"] + (data[\"Price\"] * 0.05).round(2)\n",
        "\n",
        "    X = data[[\"Price\", \"Discount\"]]\n",
        "    y = data[\"Predicted_Discount\"]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = RandomForestRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "# Forecast discounts using ARIMA\n",
        "def forecast_discounts_arima(data, future_days=5):\n",
        "    \"\"\"\n",
        "    Forecast future discounts using ARIMA.\n",
        "    :param data: DataFrame containing historical discount data (with a datetime index).\n",
        "    :param future_days: Number of days to forecast.\n",
        "    :return: DataFrame with historical and forecasted discounts.\n",
        "    \"\"\"\n",
        "    data = data.sort_index()\n",
        "    data[\"Discount\"] = pd.to_numeric(data[\"Discount\"], errors=\"coerce\")\n",
        "    data = data.dropna(subset=[\"Discount\"])\n",
        "\n",
        "    discount_series = data[\"Discount\"]\n",
        "\n",
        "    if not isinstance(data.index, pd.DatetimeIndex):\n",
        "        try:\n",
        "            data.index = pd.to_datetime(data.index)\n",
        "        except Exception as e:\n",
        "            raise ValueError(\"Index must be datetime or convertible to datetime.\") from e\n",
        "\n",
        "    model = ARIMA(discount_series, order=(5, 1, 0))\n",
        "    model_fit = model.fit()\n",
        "\n",
        "    forecast = model_fit.forecast(steps=future_days)\n",
        "    future_dates = pd.date_range(\n",
        "        start=discount_series.index[-1] + pd.Timedelta(days=1),\n",
        "        periods=future_days\n",
        "    )\n",
        "\n",
        "    forecast_df = pd.DataFrame({\"Date\": future_dates, \"Predicted_Discount\": forecast})\n",
        "    forecast_df.set_index(\"Date\", inplace=True)\n",
        "    return forecast_df\n",
        "\n",
        "# Send notifications to Slack\n",
        "def send_to_slack(data):\n",
        "    payload = {\"text\": data}\n",
        "    response = requests.post(\n",
        "        SLACK_WEBHOOK,\n",
        "        data=json.dumps(payload),\n",
        "        headers={\"Content-Type\": \"application/json\"}\n",
        "    )\n",
        "    if response.status_code != 200:\n",
        "        st.write(f\"Failed to send notification to Slack: {response.status_code}\")\n",
        "\n",
        "# Generate strategy recommendations using an LLM\n",
        "def generate_strategy_recommendation(product_name, competitor_data, sentiment):\n",
        "    \"\"\"Generate strategic recommendations using an LLM.\"\"\"\n",
        "    date = datetime.now()\n",
        "    prompt = f\"\"\"\n",
        "    You are a highly skilled business strategist specializing in e-commerce. Based on the following details, suggest actionable strategies:\n",
        "\n",
        "    *Product Name*: {product_name}\n",
        "    *Competitor Data* (including current prices, discounts, and predicted discounts):\n",
        "    {competitor_data}\n",
        "    *Sentiment Analysis*: {sentiment}\n",
        "    *Today's Date*: {str(date)}\n",
        "\n",
        "    # Task:\n",
        "    - Analyze the competitor data and identify key pricing trends.\n",
        "    - Leverage sentiment analysis insights to highlight areas where customer satisfaction can be improved.\n",
        "    - Use the discount predictions to suggest how pricing strategies can be optimized over the next 5 days.\n",
        "    - Recommend promotional campaigns or marketing strategies that align with customer sentiments and competitive trends.\n",
        "\n",
        "    Provide your recommendations in a structured format:\n",
        "    - **Pricing Strategy**\n",
        "    - **Promotional Campaign Ideas**\n",
        "    - **Customer Satisfaction Recommendations**\n",
        "    \"\"\"\n",
        "\n",
        "    data = {\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"model\": \"llama3-8b-8192\",\n",
        "        \"temperature\": 0,\n",
        "    }\n",
        "\n",
        "    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {API_KEY}\"}\n",
        "    res = requests.post(\n",
        "        \"https://api.groq.com/openai/v1/chat/completions\",\n",
        "        data=json.dumps(data),\n",
        "        headers=headers,\n",
        "    )\n",
        "    res = res.json()\n",
        "    response = res[\"choices\"][0][\"message\"][\"content\"]\n",
        "    return response\n",
        "\n",
        "# Streamlit UI\n",
        "\n",
        "st.sidebar.header(\"❄️Select a Product❄️\")\n",
        "\n",
        "products = [\n",
        "    \"Apple AirPods Pro (2nd Generation)\",\n",
        "    \"Sony WH-1000XM4 Wireless Noise Cancelling Headphones\",\n",
        "    \"Samsung Galaxy Buds2 Pro\",\n",
        "    \"Jabra Elite 85t True Wireless Earbuds\"\n",
        "]\n",
        "selected_product = st.sidebar.selectbox(\"Choose a product to analyze:\", products)\n",
        "\n",
        "competitor_data = load_competitor_data()\n",
        "reviews_data = load_reviews_data()\n",
        "\n",
        "product_data = competitor_data[competitor_data[\"product_name\"] == selected_product]\n",
        "product_reviews = reviews_data[reviews_data[\"product_name\"] == selected_product]\n",
        "\n",
        "st.header(f\"Competitor Analysis for {selected_product}\")\n",
        "st.subheader(\"Competitor Data\")\n",
        "st.table(product_data.tail(5))\n",
        "\n",
        "if not product_reviews.empty:\n",
        "    product_reviews[\"reviews\"] = product_reviews[\"reviews\"].apply(\n",
        "        lambda x: truncate_text(x, 512)\n",
        "    )\n",
        "    reviews = product_reviews[\"reviews\"].tolist()\n",
        "    sentiments = analyze_sentiment(reviews)\n",
        "\n",
        "    st.subheader(\"Customer Sentiment Analysis\")\n",
        "    sentiment_df = pd.DataFrame(sentiments)\n",
        "    fig = px.bar(sentiment_df, x=\"label\", title=\"Sentiment Analysis Results\")\n",
        "    st.plotly_chart(fig)\n",
        "else:\n",
        "    st.write(\"No reviews available for this product.\")\n",
        "\n",
        "product_data[\"Date\"] = pd.to_datetime(product_data[\"Date\"], errors=\"coerce\")\n",
        "product_data = product_data.dropna(subset=[\"Date\"])\n",
        "product_data.set_index(\"Date\", inplace=True)\n",
        "product_data[\"Discount\"] = pd.to_numeric(product_data[\"Discount\"], errors=\"coerce\")\n",
        "product_data = product_data.dropna(subset=[\"Discount\"])\n",
        "\n",
        "# Forecasting Model\n",
        "product_data_with_predictions = forecast_discounts_arima(product_data)\n",
        "\n",
        "st.subheader(\"Competitor Current and Predicted Discounts\")\n",
        "st.table(product_data_with_predictions.tail(10))\n",
        "\n",
        "recommendations = generate_strategy_recommendation(\n",
        "    selected_product,\n",
        "    product_data_with_predictions,\n",
        "    sentiments if not product_reviews.empty else \"No reviews available\",\n",
        ")\n",
        "\n",
        "st.subheader(\"Strategic Recommendations\")\n",
        "st.write(recommendations)\n",
        "\n",
        "send_to_slack(recommendations)"
      ]
    }
  ]
}